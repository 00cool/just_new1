{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNAN(df):\n",
    "    df['fico'] = df['fico'].fillna(9999)\n",
    "    df['flag_fthb']=df['flag_fthb'].fillna('X')\n",
    "    df['cd_msa']=df['cd_msa'].fillna(0)\n",
    "    df['mi_pct']=df['mi_pct'].fillna(999)\n",
    "    df['cnt_units']=df['cnt_units'].fillna(99)\n",
    "    df['occpy_sts']=df['occpy_sts'].fillna('X')\n",
    "    df['cltv']=df['cltv'].fillna(999)\n",
    "    df['dti']=df['dti'].fillna(999)\n",
    "    df['ltv']=df['ltv'].fillna(999)\n",
    "    df['channel']=df['channel'].fillna('X')\n",
    "    df['ppmt_pnlty']=df['ppmt_pnlty'].fillna('X')\n",
    "    df['prod_type']= df['prod_type'].fillna('X')\n",
    "    df['prop_type']=df['prop_type'].fillna('XX')\n",
    "    df['zipcode']=df['zipcode'].fillna('999999')\n",
    "    df['loan_purpose']=df['loan_purpose'].fillna('X')\n",
    "    df['cnt_borr']=df['cnt_borr'].fillna('99')\n",
    "    df['flag_sc']=df['flag_sc'].fillna('X')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedatatype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']] = df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']].astype('float64')\n",
    "    df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']] = df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNA(df):\n",
    "    df['delq_sts'] = df['delq_sts'].fillna('XX')\n",
    "    df['loan_age'] = df['loan_age'].fillna(999)\n",
    "    df['mths_remng'] = df['mths_remng'].fillna('XX')\n",
    "    df['repch_flag']=df['repch_flag'].fillna('X')\n",
    "    df['flag_mod']=df['flag_mod'].fillna('X')\n",
    "    df['cd_zero_bal']=df['cd_zero_bal'].fillna('00')\n",
    "    df['dt_zero_bal']=df['dt_zero_bal'].fillna('189901')\n",
    "    df['non_int_brng_upb']=df['non_int_brng_upb'].fillna(0)\n",
    "    df['dt_lst_pi']=df['dt_lst_pi'].fillna('189901')\n",
    "    df['mi_recoveries']=df['mi_recoveries'].fillna(0)\n",
    "    df['net_sale_proceeds']=df['net_sale_proceeds'].fillna('0')\n",
    "    df['non_mi_recoveries']=df['non_mi_recoveries'].fillna(0)\n",
    "    df['expenses']=df['expenses'].fillna(0)\n",
    "    df['legal_costs']=df['legal_costs'].fillna(0)\n",
    "    df['maint_pres_costs']=df['maint_pres_costs'].fillna(0)\n",
    "    df['taxes_ins_costs']=df['taxes_ins_costs'].fillna(0)\n",
    "    df['misc_costs']=df['misc_costs'].fillna(0)\n",
    "    df['actual_loss']=df['actual_loss'].fillna(0)\n",
    "    df['modcost']=df['modcost'].fillna(0)\n",
    "    df['stepmod_ind']=df['stepmod_ind'].fillna('X')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedtype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']] = df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']].astype('float64')\n",
    "    df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']] = df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chnge_code_zero(x):\n",
    "    if x=='00':\n",
    "        return 'C'\n",
    "    elif x=='01':\n",
    "        return 'P'\n",
    "    elif x=='06':\n",
    "        return 'R'\n",
    "    elif x=='03':\n",
    "        return 'S'\n",
    "    elif x=='09':\n",
    "        return 'F'\n",
    "def chnge_delinquecy(x):\n",
    "    if x=='0':\n",
    "        return 'C'\n",
    "    elif x not in list(map(str,list(range(1,9))))+['R']:\n",
    "        return '9+'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig_summary_statistics(x):\n",
    "    names = {\n",
    "        'loan_count': x['id_loan'].count(),\n",
    "        'total_orig_UPB ($B)':  x['orig_upb'].sum()/1000000000,\n",
    "        'average_orig_UPB':  x['orig_upb'].mean(),\n",
    "        'weighted_average_fico':  (x.loc[x.fico!=9999,'orig_upb'] * x.loc[x.fico!=9999,'fico']).sum()/x.loc[x.fico!=9999,'orig_upb'].sum(),\n",
    "        'weighted_average_cltv':  (x.loc[x.cltv!=999,'orig_upb'] * x.loc[x.cltv!=999,'cltv']).sum()/x.loc[x.cltv!=999,'orig_upb'].sum(),\n",
    "        'weighted_average_ltv':  (x.loc[x.ltv!=999,'orig_upb'] * x.loc[x.ltv!=999,'ltv']).sum()/x.loc[x.ltv!=999,'orig_upb'].sum(),\n",
    "        'weighted_average_dti':  (x.loc[x.dti!=999,'orig_upb'] * x.loc[x.dti!=999,'dti']).sum()/x.loc[x.dti!=999,'orig_upb'].sum(),\n",
    "        }\n",
    "\n",
    "    return pd.Series(names, index=['loan_count', 'total_orig_UPB ($B)', 'average_orig_UPB',\n",
    "                                   'weighted_average_fico', 'weighted_average_cltv', 'weighted_average_ltv','weighted_average_dti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_summary_statistics(x):\n",
    "    names = {\n",
    "        'loan_count': x['id_loan'].count(),\n",
    "        'prepay_loan(%)':  x.loc[x.cd_zero_bal.isin(['P','R']),'id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'default_loan(%)' :  x.loc[x.default==1,'id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'active_loan(%)':  x.loc[x.cd_zero_bal=='C','id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'cumulative_post‐default_event_repurchase(%)':  x.loc[(x.cd_zero_bal.isin(['S','F']))&(x.repch_flag=='Y'),'id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'ever_D180(%)':  x.loc[(x.delq_sts_180_upb!=0)|(x.delq_sts=='R'),'id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'D180_and_pre‐D180_credit_event(%)':  x.loc[(x.delq_sts_180_upb!=0)|(x.delq_sts=='R')|(x.default==1),'id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'cumulative_modification(%)' : x.loc[x.flag_mod=='Y','id_loan'].count()*100/x['id_loan'].count(),\n",
    "        'actuall_loss($M)':  -x.actual_loss.sum()/1000000,\n",
    "        'total_orig_UPB($B)':  x.orig_upb.sum()/1000000000,\n",
    "        'prepaid_upb(%)':  x.prepaid_upb.sum()*100/x.orig_upb.sum(),\n",
    "        'defaulted_upb(%)': x.defaulted_upb.sum()*100/x.orig_upb.sum(),\n",
    "        'current_upb(%)':  x.current_upb.sum()*100/x.orig_upb.sum(),\n",
    "        'post-defaulted_upb(%)':  x.loc[(com_df.default==1)&(x.repch_flag=='Y'),'defaulted_upb'].sum()*100/x.orig_upb.sum(),\n",
    "        'original_UPB_ever_D180(%)':  (x.delq_sts_180_upb.sum()+x.loc[(x.cd_zero_bal=='F'),'defaulted_upb'].sum()+x.loc[(x.delq_sts=='R')&(x.delq_sts_180_upb==0),'current_upb'].sum())*100/x.orig_upb.sum(),\n",
    "        'original_UPB_D180_and_pre_D180_credit_event(%)':  (x.delq_sts_180_upb.sum()+x.loc[(x.default==1),'defaulted_upb'].sum()+x.loc[(x.delq_sts=='R')&(x.delq_sts_180_upb==0),'current_upb'].sum())*100/x.orig_upb.sum(),\n",
    "        'UPB_weighted_cumulative_modification(%)':  x.loc[x.flag_mod=='Y','current_upb'].sum()*100/x.orig_upb.sum()\n",
    "    }\n",
    "\n",
    "    return pd.Series(names, index=['loan_count', 'prepay_loan(%)', 'default_loan(%)',\n",
    "                                   'active_loan(%)', 'cumulative_post‐default_event_repurchase(%)', 'ever_D180(%)'\n",
    "                                   ,'D180_and_pre‐D180_credit_event(%)','actuall_loss($M)','total_orig_UPB($B)',\n",
    "                                  'prepaid_upb(%)','defaulted_upb(%)','current_upb(%)','post-defaulted_upb(%)','original_UPB_ever_D180(%)'\n",
    "                                  ,'original_UPB_D180_and_pre_D180_credit_event(%)','UPB_weighted_cumulative_modification(%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOriginationCombined(str):\n",
    "    #print(str)\n",
    "    writeHeader1 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SampleOriginationCombined.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalOriginationCombined.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    "      \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            sample_df = pd.read_csv(f ,sep=\"|\", names=['fico','dt_first_pi','flag_fthb','dt_matr','cd_msa',\"mi_pct\",'cnt_units','occpy_sts','cltv','dti','orig_upb','ltv','int_rt','channel','ppmt_pnlty','prod_type','st', 'prop_type','zipcode','id_loan','loan_purpose', 'orig_loan_term','cnt_borr','seller_name','servicer_name','flag_sc'],skipinitialspace=True,dtype='unicode') \n",
    "            sample_df.flag_fthb[sample_df.flag_fthb=='9'] = 'X'\n",
    "            sample_df = fillNAN(sample_df)\n",
    "            sample_df = changedatatype(sample_df)\n",
    "            sample_df.dt_first_pi = pd.to_datetime(sample_df.dt_first_pi.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df.dt_matr = pd.to_datetime(sample_df.dt_matr.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df['fico_bins'] = pd.cut(sample_df.fico,[0,600,680,720,760,780,850,900,9999],include_lowest=True)\n",
    "            sample_df['cltv_bins'] = pd.cut(sample_df.cltv,[0,6,50,70,80,90,110,150,200,999],include_lowest=True)\n",
    "            sample_df['dti_bins'] = pd.cut(sample_df.dti,[0,27,36,46,65,999],include_lowest=True)\n",
    "            sample_df['ltv_bins'] = pd.cut(sample_df.ltv,[6,50,70,80,90,105,999],include_lowest=True)\n",
    "            sample_df['mi_pct_bins'] = pd.cut(sample_df.mi_pct,[0,20,30,40,55,999],include_lowest=True)\n",
    "\n",
    "            \n",
    "            sample_df['Year'] = ['19'+x if x=='99' else '20'+x for x in (sample_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "            sample_df.to_csv(file, mode='a', header=writeHeader1,index=False,encoding='utf-8')\n",
    "            writeHeader1=False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPerformanceCombined(str): \n",
    "#     print(str)\n",
    "    writeHeader2 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SamplePerformanceCombinedSummary.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalPerformanceCombinedSummary.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    " \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            perf_df = pd.read_csv(f,sep=\"|\",header=None,skipinitialspace=True,dtype='unicode')\n",
    "            perf_df.columns =['id_loan','svcg_cycle','current_upb','delq_sts','loan_age','mths_remng', 'repch_flag',\n",
    "                                          'flag_mod','cd_zero_bal', 'dt_zero_bal','current_int_rt','non_int_brng_upb','dt_lst_pi',\n",
    "                                          'mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs', \n",
    "                                          'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost','stepmod_ind']\n",
    "            #             perf_df['delq_sts'] = [ 999 if x=='R' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "            #             perf_df['delq_sts'] = [ 0 if x=='XX' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "            perf_df.loc[(perf_df.net_sale_proceeds=='U')|(perf_df.net_sale_proceeds=='C'),'net_sale_proceeds'] = '0'\n",
    "            #             perf_df['net_sale_proceeds'] = [ '0.0' if x=='C' else x for x in (perf_df['net_sale_proceeds'].apply(lambda x: x))]\n",
    "\n",
    "            #             perf_df.cd_zero_bal = perf_df.cd_zero_bal.apply(lambda x : chnge_code_zero(x))\n",
    "\n",
    "            perf_df = fillNA(perf_df)\n",
    "            perf_df = changedtype(perf_df)\n",
    "            perf_df.cd_zero_bal = perf_df.cd_zero_bal.apply(lambda x : chnge_code_zero(x))\n",
    "\n",
    "            ve =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='S')|(perf_df.cd_zero_bal=='F')].index)\n",
    "            h = ve.groupby(by='id_loan').last().reset_index()\n",
    "            defauled_upb = h.loc[h.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='S')|(perf_df.cd_zero_bal=='F')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            ve1 =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='P')|(perf_df.cd_zero_bal=='R')].index)\n",
    "            h1 = ve1.groupby(by='id_loan').last().reset_index()\n",
    "            prepaid_upb = h1.loc[h1.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='P')|(perf_df.cd_zero_bal=='R')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            lpi = perf_df.loc[(perf_df.delq_sts=='0'),['id_loan','svcg_cycle']]\n",
    "            lpi =lpi.groupby(by='id_loan').last().reset_index()\n",
    "            delq_sts_180 = perf_df.loc[(perf_df.delq_sts=='6'),['id_loan','svcg_cycle','current_upb']]\n",
    "            delq_sts_180 = delq_sts_180.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df = perf_df.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df['delq_sts_180_date'] = '189901'\n",
    "            perf_df['last_payment_date'] = '189901'\n",
    "            perf_df['delq_sts_180_upb'] = 0\n",
    "            perf_df['defaulted_upb'] = 0\n",
    "            perf_df['prepaid_upb'] = 0\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_date'] = delq_sts_180.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_upb'] = delq_sts_180.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(lpi.id_loan.values),'last_payment_date'] = lpi.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(defauled_upb.id_loan.values),'defaulted_upb'] = defauled_upb.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(prepaid_upb.id_loan.values),'prepaid_upb'] = prepaid_upb.current_upb.values\n",
    "\n",
    "            #             perf_df = perf_df.drop(perf_df[perf_df.cd_zero_bal=='06'].index)\n",
    "            #             perf_df = perf_df.drop('repch_flag',axis=1)\n",
    "\n",
    "            perf_df.dt_lst_pi = pd.to_datetime(perf_df.dt_lst_pi.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.dt_zero_bal = pd.to_datetime(perf_df.dt_zero_bal.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.delq_sts_180_date = pd.to_datetime(perf_df.delq_sts_180_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.last_payment_date = pd.to_datetime(perf_df.last_payment_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "\n",
    "            perf_df['GT_90_days_delinquecy'] = perf_df.delq_sts.values\n",
    "            perf_df['GT_90_days_delinquecy'] = perf_df['GT_90_days_delinquecy'].apply(lambda x: 0 if (x=='0') | (x=='1') | (x=='2')|(x=='XX')  else 1)\n",
    "\n",
    "            perf_df['default'] = perf_df.cd_zero_bal.values\n",
    "            perf_df['default'] = perf_df['default'].apply(lambda x: 1 if (x=='S') | (x=='F') else 0)\n",
    "\n",
    "            perf_df['prepayment']=0\n",
    "            perf_df.loc[(perf_df.cd_zero_bal=='P')&(perf_df.mths_remng!=0),'prepayment'] = 1 \n",
    "            #             de = perf_df[perf_df.default==1]\n",
    "            #             months_delinquecny = (pd.to_datetime(de.dt_zero_bal.values).year - pd.to_datetime(de.last_payment_date.values).year)*12 + (pd.to_datetime(de.dt_zero_bal.values).month - pd.to_datetime(de.last_payment_date.values).month)\n",
    "\n",
    "            perf_df['lpi2zero'] = 0\n",
    "            perf_df['delinquent_interest'] = 0\n",
    "            perf_df['net_loss'] = perf_df.actual_loss.copy()\n",
    "            perf_df['loss_severity'] = 0\n",
    "\n",
    "            c = perf_df[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01')]\n",
    "            if c.shape[0]>0:\n",
    "                o = (pd.to_datetime(c.dt_zero_bal.values).year - pd.to_datetime(c.dt_lst_pi.values).year)*12 + (pd.to_datetime(c.dt_zero_bal.values).month - pd.to_datetime(c.dt_lst_pi.values).month)\n",
    "\n",
    "                perf_df.loc[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01'),'lpi2zero'] = o\n",
    "\n",
    "                de_i = perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1)] \n",
    "                perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1),'delinquent_interest'] = (de_i.lpi2zero) * (de_i.defaulted_upb - de_i.non_int_brng_upb) * (de_i.current_int_rt - 0.35) / 1200\n",
    "\n",
    "            perf_df['total_proceeds'] = perf_df[['mi_recoveries','net_sale_proceeds', 'non_mi_recoveries']].sum(axis=1)\n",
    "\n",
    "            if perf_df[perf_df.actual_loss!=0].shape[0]>0:\n",
    "                perf_df.loc[(perf_df.actual_loss!=0),'net_loss'] = perf_df.loc[(perf_df.actual_loss!=0),['actual_loss','modcost']].T.apply(lambda x: x[0]-x[1])\n",
    "\n",
    "            perf_df.loc[perf_df.net_loss!=0,'loss_severity'] = perf_df.loc[perf_df.net_loss!=0,['defaulted_upb','net_loss']].T.apply(lambda x: x[1]/x[0])\n",
    "\n",
    "            perf_df.delq_sts = perf_df.delq_sts.apply(lambda x : chnge_delinquecy(x))\n",
    "            perf_df.to_csv(file, mode='a', header=writeHeader2,index=False,encoding='utf-8')\n",
    "            writeHeader2=False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ts = time.time()\n",
    "    foldername1= 'SampleInputFiles'\n",
    "    foldername2= 'HistoricalInputFiles' \n",
    "    \n",
    "    sampleOrigFiles=str(os.getcwd())+\"/\"+foldername1+\"/sample_orig_*.txt\"\n",
    "    samplePerfFiles=str(os.getcwd())+\"/\"+foldername1+\"/sample_svcg_*.txt\"\n",
    "    \n",
    "    historical_Files=str(os.getcwd())+\"/\"+foldername2+\"/historical_data1_Q*.txt\"\n",
    "    historical_timeFiles=str(os.getcwd())+\"/\"+foldername2+\"/historical_data1_time_Q*.txt\"\n",
    "    \n",
    "    \n",
    "    orig1_file = createOriginationCombined(sampleOrigFiles)\n",
    "    per1_file = createPerformanceCombined(samplePerfFiles)\n",
    "    \n",
    "    orig1_df = pd.read_csv(orig1_file)\n",
    "    per1_df = pd.read_csv(per1_file,dtype={'delq_sts':'str'})\n",
    "    combined_df = orig1_df.merge(per1_df,on='id_loan')\n",
    "    combined_df.to_csv('combined_SF_smaple_data.csv', index=False)\n",
    "    \n",
    "    com1_df = pd.read_csv('combined_SF_smaple_data.csv')\n",
    "\n",
    "    orig_summary_statistic1 = com1_df.groupby(\"Year\").apply(orig_summary_statistics).round(1)\n",
    "    performance_summary_statistic1 = com1_df.groupby(\"Year\").apply(performance_summary_statistics).round(1)\n",
    "   \n",
    "    orig_summary_statistic1.to_csv(\"sample_SF_orig_summary_Statistics.csv\",index=False)\n",
    "    performance_summary_statistic1.to_csv(\"sample_SF_performance_summary_Statistics.csv\",index=False)\n",
    "    \n",
    "#     orig2_file = createOriginationCombined(historical_Files)\n",
    "#     per2_file = createPerformanceCombined(historical_timeFiles)\n",
    "\n",
    "#     orig2_df = pd.read_csv(orig2_file)\n",
    "#     per2_df = pd.read_csv(per2_file,dtype={'delq_sts':'str'})\n",
    "    \n",
    "#     combined2_df = orig2_df.merge(per2_df,on='id_loan')\n",
    "#     combined2_df.to_csv('combined_SF_historical_all_data.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "#     com2_df = pd.read_csv('combined_SF_historical_all_data.csv')\n",
    "    \n",
    "#     orig_summary_statistic2 = com2_df.groupby(\"Year\").apply(orig_summary_statistics).round(1)\n",
    "#     performance_summary_statistic2 = com2_df.groupby(\"Year\").apply(performance_summary_statistics).round(1)\n",
    "\n",
    "#     orig_summary_statistic2.to_csv(\"full_SF_orig_summary_Statistics.csv\",index=False)\n",
    "#     performance_summary_statistic2.to_csv(\"full_SF_performance_summary_Statistics.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
