{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNAN(df):\n",
    "    df['fico'] = df['fico'].fillna(9999)\n",
    "    df['flag_fthb']=df['flag_fthb'].fillna('X')\n",
    "    df['cd_msa']=df['cd_msa'].fillna(0)\n",
    "    df['mi_pct']=df['mi_pct'].fillna(999)\n",
    "    df['cnt_units']=df['cnt_units'].fillna(99)\n",
    "    df['occpy_sts']=df['occpy_sts'].fillna('X')\n",
    "    df['cltv']=df['cltv'].fillna(999)\n",
    "    df['dti']=df['dti'].fillna(999)\n",
    "    df['ltv']=df['ltv'].fillna(999)\n",
    "    df['channel']=df['channel'].fillna('X')\n",
    "    df['ppmt_pnlty']=df['ppmt_pnlty'].fillna('X')\n",
    "    df['prod_type']= df['prod_type'].fillna('X')\n",
    "    df['prop_type']=df['prop_type'].fillna('XX')\n",
    "    df['zipcode']=df['zipcode'].fillna('999999')\n",
    "    df['loan_purpose']=df['loan_purpose'].fillna('X')\n",
    "    df['cnt_borr']=df['cnt_borr'].fillna('99')\n",
    "    df['flag_sc']=df['flag_sc'].fillna('X')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedatatype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']] = df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']].astype('float64')\n",
    "    df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']] = df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNA(df):\n",
    "    df['delq_sts'] = df['delq_sts'].fillna('XX')\n",
    "    df['loan_age'] = df['loan_age'].fillna(999)\n",
    "    df['mths_remng'] = df['mths_remng'].fillna('XX')\n",
    "    df['repch_flag']=df['repch_flag'].fillna('X')\n",
    "    df['flag_mod']=df['flag_mod'].fillna('X')\n",
    "    df['cd_zero_bal']=df['cd_zero_bal'].fillna('00')\n",
    "    df['dt_zero_bal']=df['dt_zero_bal'].fillna('189901')\n",
    "    df['non_int_brng_upb']=df['non_int_brng_upb'].fillna(0)\n",
    "    df['dt_lst_pi']=df['dt_lst_pi'].fillna('189901')\n",
    "    df['mi_recoveries']=df['mi_recoveries'].fillna(0)\n",
    "    df['net_sale_proceeds']=df['net_sale_proceeds'].fillna('0')\n",
    "    df['non_mi_recoveries']=df['non_mi_recoveries'].fillna(0)\n",
    "    df['expenses']=df['expenses'].fillna(0)\n",
    "    df['legal_costs']=df['legal_costs'].fillna(0)\n",
    "    df['maint_pres_costs']=df['maint_pres_costs'].fillna(0)\n",
    "    df['taxes_ins_costs']=df['taxes_ins_costs'].fillna(0)\n",
    "    df['misc_costs']=df['misc_costs'].fillna(0)\n",
    "    df['actual_loss']=df['actual_loss'].fillna(0)\n",
    "    df['modcost']=df['modcost'].fillna(0)\n",
    "    df['stepmod_ind']=df['stepmod_ind'].fillna('X')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedtype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']] = df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']].astype('float64')\n",
    "    df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']] = df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chnge_code_zero(x):\n",
    "    if x=='00':\n",
    "        return 'C'\n",
    "    elif x=='01':\n",
    "        return 'P'\n",
    "    elif x=='06':\n",
    "        return 'R'\n",
    "    elif x=='03':\n",
    "        return 'S'\n",
    "    elif x=='09':\n",
    "        return 'F'\n",
    "def chnge_delinquecy(x):\n",
    "    if x=='0':\n",
    "        return 'C'\n",
    "    elif x not in list(map(str,list(range(1,9))))+['R']:\n",
    "        return '9+'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOriginationCombined(str):\n",
    "    #print(str)\n",
    "    writeHeader1 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SampleOriginationCombined.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalOriginationCombined.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    "      \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            sample_df = pd.read_csv(f ,sep=\"|\", names=['fico','dt_first_pi','flag_fthb','dt_matr','cd_msa',\"mi_pct\",'cnt_units','occpy_sts','cltv','dti','orig_upb','ltv','int_rt','channel','ppmt_pnlty','prod_type','st', 'prop_type','zipcode','id_loan','loan_purpose', 'orig_loan_term','cnt_borr','seller_name','servicer_name','flag_sc'],skipinitialspace=True,dtype='unicode') \n",
    "            sample_df.flag_fthb[sample_df.flag_fthb=='9'] = 'X'\n",
    "            sample_df = fillNAN(sample_df)\n",
    "            sample_df = changedatatype(sample_df)\n",
    "            sample_df.dt_first_pi = pd.to_datetime(sample_df.dt_first_pi.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df.dt_matr = pd.to_datetime(sample_df.dt_matr.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df['fico_bins'] = pd.cut(sample_df.fico,[0,600,680,720,760,780,850,900,9999],include_lowest=True)\n",
    "            sample_df['cltv_bins'] = pd.cut(sample_df.cltv,[0,6,50,70,80,90,110,150,200,999],include_lowest=True)\n",
    "            sample_df['dti_bins'] = pd.cut(sample_df.dti,[0,27,36,46,65,999],include_lowest=True)\n",
    "            sample_df['ltv_bins'] = pd.cut(sample_df.ltv,[6,50,70,80,90,105,999],include_lowest=True)\n",
    "            sample_df['mi_pct_bins'] = pd.cut(sample_df.mi_pct,[0,20,30,40,55,999],include_lowest=True)\n",
    "\n",
    "            \n",
    "            sample_df['Year'] = ['19'+x if x=='99' else '20'+x for x in (sample_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "            sample_df.to_csv(file, mode='a', header=writeHeader1,index=False,encoding='utf-8')\n",
    "            writeHeader1=False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPerformanceCombined(str): \n",
    "#     print(str)\n",
    "    writeHeader2 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SamplePerformanceCombinedSummary.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalPerformanceCombinedSummary.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    " \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            perf_df = pd.read_csv(f,sep=\"|\",header=None,skipinitialspace=True,dtype='unicode')\n",
    "            perf_df.columns =['id_loan','svcg_cycle','current_upb','delq_sts','loan_age','mths_remng', 'repch_flag',\n",
    "                                          'flag_mod','cd_zero_bal', 'dt_zero_bal','current_int_rt','non_int_brng_upb','dt_lst_pi',\n",
    "                                          'mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs', \n",
    "                                          'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost','stepmod_ind']\n",
    "            #             perf_df['delq_sts'] = [ 999 if x=='R' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "            #             perf_df['delq_sts'] = [ 0 if x=='XX' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "            perf_df.loc[(perf_df.net_sale_proceeds=='U')|(perf_df.net_sale_proceeds=='C'),'net_sale_proceeds'] = '0'\n",
    "            #             perf_df['net_sale_proceeds'] = [ '0.0' if x=='C' else x for x in (perf_df['net_sale_proceeds'].apply(lambda x: x))]\n",
    "\n",
    "            #             perf_df.cd_zero_bal = perf_df.cd_zero_bal.apply(lambda x : chnge_code_zero(x))\n",
    "\n",
    "            perf_df = fillNA(perf_df)\n",
    "            perf_df = changedtype(perf_df)\n",
    "            perf_df.cd_zero_bal = perf_df.cd_zero_bal.apply(lambda x : chnge_code_zero(x))\n",
    "\n",
    "            ve =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='S')|(perf_df.cd_zero_bal=='F')].index)\n",
    "            h = ve.groupby(by='id_loan').last().reset_index()\n",
    "            defauled_upb = h.loc[h.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='S')|(perf_df.cd_zero_bal=='F')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            ve1 =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='P')].index)\n",
    "            h1 = ve1.groupby(by='id_loan').last().reset_index()\n",
    "            prepaid_upb = h1.loc[h1.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='P')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            lpi = perf_df.loc[(perf_df.delq_sts=='0'),['id_loan','svcg_cycle']]\n",
    "            lpi =lpi.groupby(by='id_loan').last().reset_index()\n",
    "            delq_sts_180 = perf_df.loc[(perf_df.delq_sts=='6'),['id_loan','svcg_cycle','current_upb']]\n",
    "            delq_sts_180 = delq_sts_180.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df = perf_df.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df['delq_sts_180_date'] = '189901'\n",
    "            perf_df['last_payment_date'] = '189901'\n",
    "            perf_df['delq_sts_180_upb'] = 0\n",
    "            perf_df['defaulted_upb'] = 0\n",
    "            perf_df['prepaid_upb'] = 0\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_date'] = delq_sts_180.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_upb'] = delq_sts_180.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(lpi.id_loan.values),'last_payment_date'] = lpi.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(defauled_upb.id_loan.values),'defaulted_upb'] = defauled_upb.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(prepaid_upb.id_loan.values),'prepaid_upb'] = prepaid_upb.current_upb.values\n",
    "\n",
    "            #             perf_df = perf_df.drop(perf_df[perf_df.cd_zero_bal=='06'].index)\n",
    "            #             perf_df = perf_df.drop('repch_flag',axis=1)\n",
    "\n",
    "            perf_df.dt_lst_pi = pd.to_datetime(perf_df.dt_lst_pi.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.dt_zero_bal = pd.to_datetime(perf_df.dt_zero_bal.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.delq_sts_180_date = pd.to_datetime(perf_df.delq_sts_180_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.last_payment_date = pd.to_datetime(perf_df.last_payment_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "\n",
    "            perf_df['GT_90_days_delinquecy'] = perf_df.delq_sts.values\n",
    "            perf_df['GT_90_days_delinquecy'] = perf_df['GT_90_days_delinquecy'].apply(lambda x: 0 if (x=='0') | (x=='1') | (x=='2')|(x=='XX')  else 1)\n",
    "\n",
    "            perf_df['default'] = perf_df.cd_zero_bal.values\n",
    "            perf_df['default'] = perf_df['default'].apply(lambda x: 1 if (x=='S') | (x=='F') else 0)\n",
    "\n",
    "            perf_df['prepayment']=0\n",
    "            perf_df.loc[(perf_df.cd_zero_bal=='P')&(perf_df.mths_remng!=0),'prepayment'] = 1 \n",
    "            #             de = perf_df[perf_df.default==1]\n",
    "            #             months_delinquecny = (pd.to_datetime(de.dt_zero_bal.values).year - pd.to_datetime(de.last_payment_date.values).year)*12 + (pd.to_datetime(de.dt_zero_bal.values).month - pd.to_datetime(de.last_payment_date.values).month)\n",
    "\n",
    "            perf_df['lpi2zero'] = 0\n",
    "            perf_df['delinquent_interest'] = 0\n",
    "            perf_df['net_loss'] = perf_df.actual_loss.copy()\n",
    "            perf_df['loss_severity'] = 0\n",
    "\n",
    "            c = perf_df[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01')]\n",
    "            if c.shape[0]>0:\n",
    "                o = (pd.to_datetime(c.dt_zero_bal.values).year - pd.to_datetime(c.dt_lst_pi.values).year)*12 + (pd.to_datetime(c.dt_zero_bal.values).month - pd.to_datetime(c.dt_lst_pi.values).month)\n",
    "\n",
    "                perf_df.loc[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01'),'lpi2zero'] = o\n",
    "\n",
    "                de_i = perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1)] \n",
    "                perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1),'delinquent_interest'] = (de_i.lpi2zero) * (de_i.defaulted_upb - de_i.non_int_brng_upb) * (de_i.current_int_rt - 0.35) / 1200\n",
    "\n",
    "            perf_df['total_proceeds'] = perf_df[['mi_recoveries','net_sale_proceeds', 'non_mi_recoveries']].sum(axis=1)\n",
    "\n",
    "            if perf_df[perf_df.actual_loss!=0].shape[0]>0:\n",
    "                perf_df.loc[(perf_df.actual_loss!=0),'net_loss'] = perf_df.loc[(perf_df.actual_loss!=0),['actual_loss','modcost']].T.apply(lambda x: x[0]-x[1])\n",
    "\n",
    "            perf_df.loc[perf_df.net_loss!=0,'loss_severity'] = perf_df.loc[perf_df.net_loss!=0,['defaulted_upb','net_loss']].T.apply(lambda x: x[1]/x[0])\n",
    "\n",
    "            perf_df.delq_sts = perf_df.delq_sts.apply(lambda x : chnge_delinquecy(x))\n",
    "            perf_df.to_csv(file, mode='a', header=writeHeader2,index=False,encoding='utf-8')\n",
    "            writeHeader2=False\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ts = time.time()\n",
    "    foldername1= 'SampleInputFiles'\n",
    "    foldername2= 'HistoricalInputFiles' \n",
    "    \n",
    "    sampleOrigFiles=str(os.getcwd())+\"/\"+foldername1+\"/sample_orig_*.txt\"\n",
    "    samplePerfFiles=str(os.getcwd())+\"/\"+foldername1+\"/sample_svcg_*.txt\"\n",
    "    \n",
    "    historical_Files=str(os.getcwd())+\"/\"+foldername2+\"/historical_data1_*.txt\"\n",
    "    historical_timeFiles=str(os.getcwd())+\"/\"+foldername2+\"/historical_data1_*.txt\"\n",
    "    \n",
    "    \n",
    "    orig1_file = createOriginationCombined(sampleOrigFiles)\n",
    "    per1_file = createPerformanceCombined(samplePerfFiles)\n",
    "    \n",
    "    orig1_df = pd.read_csv(orig1_file)\n",
    "    per1_df = pd.read_csv(per1_file,dtype={'delq_sts':'str'})\n",
    "    combined_df = orig1_df.merge(per1_df,on='id_loan')\n",
    "    combined_df.to_csv('combined_SF_smaple_data.csv', index=False)\n",
    "    \n",
    "#     orig2_file = createOriginationCombined(historical_Files)\n",
    "#     per2_file = createPerformanceCombined(historical_timeFiles)\n",
    "\n",
    "#     orig2_df = pd.read_csv(orig2_file)\n",
    "#     per2_df = pd.read_csv(per2_file,dtype={'delq_sts':'str'})\n",
    "    \n",
    "#     combined2_df = orig2_df.merge(per2_df,on='id_loan')\n",
    "#     combined2_df.to_csv('combined_SF_historical_all_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]\n",
      "Working on  sample_orig_1999.txt:   0%|                                                         | 0/19 [00:00<?, ?it/s]\n",
      "Working on  sample_orig_1999.txt:   5%|██▌                                              | 1/19 [00:02<00:49,  2.75s/it]\n",
      "Working on  sample_orig_2000.txt:   5%|██▌                                              | 1/19 [00:02<00:49,  2.75s/it]\n",
      "Working on  sample_orig_2000.txt:  11%|█████▏                                           | 2/19 [00:05<00:47,  2.80s/it]\n",
      "Working on  sample_orig_2001.txt:  11%|█████▏                                           | 2/19 [00:05<00:47,  2.81s/it]\n",
      "Working on  sample_orig_2001.txt:  16%|███████▋                                         | 3/19 [00:08<00:45,  2.85s/it]\n",
      "Working on  sample_orig_2002.txt:  16%|███████▋                                         | 3/19 [00:08<00:45,  2.85s/it]\n",
      "Working on  sample_orig_2002.txt:  21%|██████████▎                                      | 4/19 [00:11<00:43,  2.87s/it]\n",
      "Working on  sample_orig_2003.txt:  21%|██████████▎                                      | 4/19 [00:11<00:43,  2.88s/it]\n",
      "Working on  sample_orig_2003.txt:  26%|████████████▉                                    | 5/19 [00:14<00:40,  2.88s/it]\n",
      "Working on  sample_orig_2004.txt:  26%|████████████▉                                    | 5/19 [00:14<00:40,  2.88s/it]\n",
      "Working on  sample_orig_2004.txt:  32%|███████████████▍                                 | 6/19 [00:17<00:37,  2.87s/it]\n",
      "Working on  sample_orig_2005.txt:  32%|███████████████▍                                 | 6/19 [00:17<00:37,  2.87s/it]\n",
      "Working on  sample_orig_2005.txt:  37%|██████████████████                               | 7/19 [00:20<00:34,  2.90s/it]\n",
      "Working on  sample_orig_2006.txt:  37%|██████████████████                               | 7/19 [00:20<00:34,  2.90s/it]\n",
      "Working on  sample_orig_2006.txt:  42%|████████████████████▋                            | 8/19 [00:23<00:31,  2.90s/it]\n",
      "Working on  sample_orig_2007.txt:  42%|████████████████████▋                            | 8/19 [00:23<00:31,  2.90s/it]\n",
      "Working on  sample_orig_2007.txt:  47%|███████████████████████▏                         | 9/19 [00:26<00:29,  2.91s/it]\n",
      "Working on  sample_orig_2008.txt:  47%|███████████████████████▏                         | 9/19 [00:26<00:29,  2.91s/it]\n",
      "Working on  sample_orig_2008.txt:  53%|█████████████████████████▎                      | 10/19 [00:28<00:26,  2.89s/it]\n",
      "Working on  sample_orig_2009.txt:  53%|█████████████████████████▎                      | 10/19 [00:28<00:26,  2.89s/it]\n",
      "Working on  sample_orig_2009.txt:  58%|███████████████████████████▊                    | 11/19 [00:31<00:23,  2.90s/it]\n",
      "Working on  sample_orig_2010.txt:  58%|███████████████████████████▊                    | 11/19 [00:31<00:23,  2.90s/it]\n",
      "Working on  sample_orig_2010.txt:  63%|██████████████████████████████▎                 | 12/19 [00:34<00:20,  2.90s/it]\n",
      "Working on  sample_orig_2011.txt:  63%|██████████████████████████████▎                 | 12/19 [00:34<00:20,  2.90s/it]\n",
      "Working on  sample_orig_2011.txt:  68%|████████████████████████████████▊               | 13/19 [00:37<00:17,  2.90s/it]\n",
      "Working on  sample_orig_2012.txt:  68%|████████████████████████████████▊               | 13/19 [00:37<00:17,  2.90s/it]\n",
      "Working on  sample_orig_2012.txt:  74%|███████████████████████████████████▎            | 14/19 [00:40<00:14,  2.89s/it]\n",
      "Working on  sample_orig_2013.txt:  74%|███████████████████████████████████▎            | 14/19 [00:40<00:14,  2.89s/it]\n",
      "Working on  sample_orig_2013.txt:  79%|█████████████████████████████████████▉          | 15/19 [00:43<00:11,  2.88s/it]\n",
      "Working on  sample_orig_2014.txt:  79%|█████████████████████████████████████▉          | 15/19 [00:43<00:11,  2.88s/it]\n",
      "Working on  sample_orig_2014.txt:  84%|████████████████████████████████████████▍       | 16/19 [00:46<00:08,  2.88s/it]\n",
      "Working on  sample_orig_2015.txt:  84%|████████████████████████████████████████▍       | 16/19 [00:46<00:08,  2.88s/it]\n",
      "Working on  sample_orig_2015.txt:  89%|██████████████████████████████████████████▉     | 17/19 [00:48<00:05,  2.87s/it]\n",
      "Working on  sample_orig_2016.txt:  89%|██████████████████████████████████████████▉     | 17/19 [00:48<00:05,  2.87s/it]\n",
      "Working on  sample_orig_2016.txt:  95%|█████████████████████████████████████████████▍  | 18/19 [00:51<00:02,  2.88s/it]\n",
      "Working on  sample_orig_2017.txt:  95%|█████████████████████████████████████████████▍  | 18/19 [00:51<00:02,  2.88s/it]\n",
      "Working on  sample_orig_2017.txt: 100%|████████████████████████████████████████████████| 19/19 [00:52<00:00,  2.78s/it]\n",
      "\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]\n",
      "Working on  sample_svcg_1999.txt:   0%|                                                         | 0/19 [00:00<?, ?it/s]\n",
      "Working on  sample_svcg_1999.txt:   5%|██▌                                              | 1/19 [00:40<12:01, 40.08s/it]\n",
      "Working on  sample_svcg_2000.txt:   5%|██▌                                              | 1/19 [00:40<12:01, 40.08s/it]\n",
      "Working on  sample_svcg_2000.txt:  11%|█████▏                                           | 2/19 [00:59<08:29, 30.00s/it]\n",
      "Working on  sample_svcg_2001.txt:  11%|█████▏                                           | 2/19 [00:59<08:29, 30.00s/it]\n",
      "Working on  sample_svcg_2001.txt:  16%|███████▋                                         | 3/19 [01:24<07:31, 28.21s/it]\n",
      "Working on  sample_svcg_2002.txt:  16%|███████▋                                         | 3/19 [01:24<07:31, 28.21s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf = pd.read_csv('SamplePerformanceCombinedSummary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0         894456\n",
       "-67410.0          4\n",
       "-75880.0          3\n",
       "-68.0             3\n",
       "-104341.0         3\n",
       "-80800.0          3\n",
       "-94375.0          3\n",
       "-12049.0          3\n",
       "-54992.0          3\n",
       "-71123.0          3\n",
       "-21933.0          3\n",
       "-21915.0          3\n",
       "-48674.0          3\n",
       "-44514.0          3\n",
       "-20696.0          3\n",
       "-19973.0          3\n",
       "-8486.0           3\n",
       "-12772.0          3\n",
       "-20876.0          3\n",
       "-75082.0          3\n",
       "-1817.0           3\n",
       "-83648.0          3\n",
       "-56526.0          3\n",
       "-12632.0          3\n",
       "-37601.0          3\n",
       "-37182.0          3\n",
       "-43061.0          3\n",
       "-60505.0          3\n",
       "-25862.0          3\n",
       "-66406.0          3\n",
       "              ...  \n",
       "-20636.0          1\n",
       "-82618.0          1\n",
       "-82612.0          1\n",
       "-82601.0          1\n",
       "-82600.0          1\n",
       "-20649.0          1\n",
       "-82589.0          1\n",
       "-21247.0          1\n",
       "-82567.0          1\n",
       "-82562.0          1\n",
       "-82561.0          1\n",
       "-1290.0           1\n",
       "-82551.0          1\n",
       "-82549.0          1\n",
       "-82536.0          1\n",
       "-82457.0          1\n",
       "-82528.0          1\n",
       "-82526.0          1\n",
       "-82519.0          1\n",
       "-82514.0          1\n",
       "-20626.0          1\n",
       "-82502.0          1\n",
       "-82496.0          1\n",
       "-82495.0          1\n",
       "-20623.0          1\n",
       "-82479.0          1\n",
       "-82478.0          1\n",
       "-82471.0          1\n",
       "-82468.0          1\n",
       "-16401.0          1\n",
       "Name: actual_loss, Length: 17113, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prf.actual_loss.copy().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = pd.read_csv('combined_SF_smaple_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN          831999\n",
       " 0.000000     62457\n",
       "-0.746026         1\n",
       "-0.172151         1\n",
       "-0.391333         1\n",
       "-0.592554         1\n",
       "-0.596223         1\n",
       " 0.070438         1\n",
       "-0.435688         1\n",
       "-1.195395         1\n",
       "-1.147339         1\n",
       "-0.868884         1\n",
       "-0.392280         1\n",
       "-0.195975         1\n",
       "-0.450627         1\n",
       "-0.630259         1\n",
       "-0.312459         1\n",
       "-0.375139         1\n",
       "-0.588490         1\n",
       "-0.405654         1\n",
       " 0.023456         1\n",
       "-0.847381         1\n",
       "-1.301309         1\n",
       "-0.542672         1\n",
       "-1.080376         1\n",
       "-0.233510         1\n",
       "-0.489017         1\n",
       "-0.833105         1\n",
       "-0.475519         1\n",
       "-0.389084         1\n",
       "              ...  \n",
       "-0.424426         1\n",
       "-0.425905         1\n",
       "-0.332945         1\n",
       "-0.812443         1\n",
       "-0.336838         1\n",
       "-0.578067         1\n",
       "-0.841778         1\n",
       "-0.272126         1\n",
       "-0.028202         1\n",
       "-0.152497         1\n",
       "-0.967642         1\n",
       " 0.140136         1\n",
       "-0.118027         1\n",
       "-0.317250         1\n",
       "-0.649727         1\n",
       "-1.284381         1\n",
       "-0.909267         1\n",
       "-0.565549         1\n",
       "-0.233358         1\n",
       "-0.088720         1\n",
       "-0.004027         1\n",
       "-0.229813         1\n",
       "-0.199914         1\n",
       "-0.439604         1\n",
       "-1.097720         1\n",
       "-0.220213         1\n",
       "-0.527644         1\n",
       "-0.560733         1\n",
       "-0.300270         1\n",
       "-0.060480         1\n",
       "Name: loss_severity, Length: 17969, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com.loss_severity.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com[com.total_costs!=0].shape[0] - com[com.expenses!=0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com.shape[0] - com[com.actual_loss==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com.loc[(com.actual_loss!=0),['actual_loss','modcost']].T.apply(lambda x: x[0]-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com[com.actual_loss!=0].shape[0] , com[(com.actual_loss!=0) & (com.modcost!=0) ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(com.actual_loss - com.modcost).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
