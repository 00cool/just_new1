{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNAN(df):\n",
    "    df['fico'] = df['fico'].fillna(9999)\n",
    "    df['flag_fthb']=df['flag_fthb'].fillna('X')\n",
    "    df['cd_msa']=df['cd_msa'].fillna(0)\n",
    "    df['mi_pct']=df['mi_pct'].fillna(999)\n",
    "    df['cnt_units']=df['cnt_units'].fillna(99)\n",
    "    df['occpy_sts']=df['occpy_sts'].fillna('X')\n",
    "    df['cltv']=df['cltv'].fillna(999)\n",
    "    df['dti']=df['dti'].fillna(999)\n",
    "    df['ltv']=df['ltv'].fillna(999)\n",
    "    df['channel']=df['channel'].fillna('X')\n",
    "    df['ppmt_pnlty']=df['ppmt_pnlty'].fillna('X')\n",
    "    df['prod_type']= df['prod_type'].fillna('X')\n",
    "    df['prop_type']=df['prop_type'].fillna('XX')\n",
    "    df['zipcode']=df['zipcode'].fillna('999999')\n",
    "    df['loan_purpose']=df['loan_purpose'].fillna('X')\n",
    "    df['cnt_borr']=df['cnt_borr'].fillna('99')\n",
    "    df['flag_sc']=df['flag_sc'].fillna('X')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedatatype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']] = df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']].astype('float64')\n",
    "    df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']] = df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNA(df):\n",
    "    df['delq_sts'] = df['delq_sts'].fillna('XX')\n",
    "    df['loan_age'] = df['loan_age'].fillna(999)\n",
    "    df['mths_remng'] = df['mths_remng'].fillna('XX')\n",
    "    df['repch_flag']=df['repch_flag'].fillna('X')\n",
    "    df['flag_mod']=df['flag_mod'].fillna('X')\n",
    "    df['cd_zero_bal']=df['cd_zero_bal'].fillna('00')\n",
    "    df['dt_zero_bal']=df['dt_zero_bal'].fillna('189901')\n",
    "    df['non_int_brng_upb']=df['non_int_brng_upb'].fillna(0)\n",
    "    df['dt_lst_pi']=df['dt_lst_pi'].fillna('189901')\n",
    "    df['mi_recoveries']=df['mi_recoveries'].fillna(0)\n",
    "    df['net_sale_proceeds']=df['net_sale_proceeds'].fillna('-999.0')\n",
    "    df['non_mi_recoveries']=df['non_mi_recoveries'].fillna(0)\n",
    "    df['expenses']=df['expenses'].fillna(0)\n",
    "    df['legal_costs']=df['legal_costs'].fillna(0)\n",
    "    df['maint_pres_costs']=df['maint_pres_costs'].fillna(0)\n",
    "    df['taxes_ins_costs']=df['taxes_ins_costs'].fillna(0)\n",
    "    df['misc_costs']=df['misc_costs'].fillna(0)\n",
    "    df['actual_loss']=df['actual_loss'].fillna(0)\n",
    "    df['modcost']=df['modcost'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changedtype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']] = df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']].astype('float64')\n",
    "    df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']] = df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOriginationCombined(str):\n",
    "    #print(str)\n",
    "    writeHeader1 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SampleOriginationCombined.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalOriginationCombined.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    "      \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            sample_df = pd.read_csv(f ,sep=\"|\", names=['fico','dt_first_pi','flag_fthb','dt_matr','cd_msa',\"mi_pct\",'cnt_units','occpy_sts','cltv','dti','orig_upb','ltv','int_rt','channel','ppmt_pnlty','prod_type','st', 'prop_type','zipcode','id_loan','loan_purpose', 'orig_loan_term','cnt_borr','seller_name','servicer_name','flag_sc'],skipinitialspace=True,dtype='unicode') \n",
    "            sample_df.flag_fthb[sample_df.flag_fthb=='9'] = 'X'\n",
    "            sample_df = fillNAN(sample_df)\n",
    "            sample_df = changedatatype(sample_df)\n",
    "            sample_df.dt_first_pi = pd.to_datetime(sample_df.dt_first_pi.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df.dt_matr = pd.to_datetime(sample_df.dt_matr.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df['fico_bins'] = pd.cut(sample_df.fico[sample_df.fico<9999],5,include_lowest=True)\n",
    "            sample_df['cltv_bins'] = pd.cut(sample_df.cltv[sample_df.cltv<999],7,include_lowest=True)\n",
    "            sample_df['dti_bins'] = pd.cut(sample_df.dti[sample_df.dti<999],5,include_lowest=True)\n",
    "            sample_df['ltv_bins'] = pd.cut(sample_df.ltv[sample_df.ltv<999],5,include_lowest=True)\n",
    "            \n",
    "            sample_df['Year'] = ['19'+x if x=='99' else '20'+x for x in (sample_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "            perf_df.to_csv(file, mode='a', header=writeHeader1,index=False,encoding='utf-8')\n",
    "            writeHeader1=False\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPerformanceCombined(str): \n",
    "#     print(str)\n",
    "    writeHeader2 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SamplePerformanceCombinedSummary.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalPerformanceCombinedSummary.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    " \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            perf_df = pd.read_csv(f,sep=\"|\",header=None,skipinitialspace=True,dtype='unicode')\n",
    "            perf_df.columns =['id_loan','svcg_cycle','current_upb','delq_sts','loan_age','mths_remng', 'repch_flag',\n",
    "                              'flag_mod','cd_zero_bal', 'dt_zero_bal','current_int_rt','non_int_brng_upb','dt_lst_pi',\n",
    "                              'mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs', \n",
    "                              'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost','stepmod_ind']\n",
    "#             perf_df['delq_sts'] = [ 999 if x=='R' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "#             perf_df['delq_sts'] = [ 0 if x=='XX' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "            perf_df.loc[(perf_df.net_sale_proceeds=='U')|(perf_df.net_sale_proceeds=='C'),'net_sale_proceeds'] = '0.0'\n",
    "#             perf_df['net_sale_proceeds'] = [ '0.0' if x=='C' else x for x in (perf_df['net_sale_proceeds'].apply(lambda x: x))]\n",
    "\n",
    "            perf_df = fillNA(perf_df)\n",
    "            perf_df = changedtype(perf_df)\n",
    "\n",
    "            ve =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='03')|(perf_df.cd_zero_bal=='09')].index)\n",
    "            h = ve.groupby(by='id_loan').last().reset_index()\n",
    "            defauled_upb = h.loc[h.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='03')|(perf_df.cd_zero_bal=='09')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            ve1 =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='01')].index)\n",
    "            h1 = ve1.groupby(by='id_loan').last().reset_index()\n",
    "            prepaid_upb = h1.loc[h1.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='01')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            lpi = perf_df.loc[(perf_df.delq_sts=='0'),['id_loan','svcg_cycle']]\n",
    "            lpi =lpi.groupby(by='id_loan').last().reset_index()\n",
    "            delq_sts_180 = perf_df.loc[(perf_df.delq_sts=='6'),['id_loan','svcg_cycle','current_upb']]\n",
    "            delq_sts_180 = delq_sts_180.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df = perf_df.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df['delq_sts_180_date'] = '189901'\n",
    "            perf_df['last_payment_date'] = '189901'\n",
    "            perf_df['delq_sts_180_upb'] = 0\n",
    "            perf_df['defaulted_upb'] = 0\n",
    "            perf_df['prepaid_upb'] = 0\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_date'] = delq_sts_180.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_upb'] = delq_sts_180.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(lpi.id_loan.values),'last_payment_date'] = lpi.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(defauled_upb.id_loan.values),'defaulted_upb'] = defauled_upb.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(prepaid_upb.id_loan.values),'prepaid_upb'] = prepaid_upb.current_upb.values\n",
    "\n",
    "#             perf_df = perf_df.drop(perf_df[perf_df.cd_zero_bal=='06'].index)\n",
    "#             perf_df = perf_df.drop('repch_flag',axis=1)\n",
    "\n",
    "            perf_df.dt_lst_pi = pd.to_datetime(perf_df.dt_lst_pi.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.dt_zero_bal = pd.to_datetime(perf_df.dt_zero_bal.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.delq_sts_180_date = pd.to_datetime(perf_df.delq_sts_180_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.last_payment_date = pd.to_datetime(perf_df.last_payment_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "\n",
    "            perf_df['GT_90_days_deliquecy'] = perf_df.delq_sts.values\n",
    "            perf_df['GT_90_days_deliquecy'] = perf_df['GT_90_days_deliquecy'].apply(lambda x: 0 if (x=='0') | (x=='1') | (x=='2')|(x=='XX')  else 1)\n",
    "\n",
    "            perf_df['default'] = perf_df.cd_zero_bal.values\n",
    "            perf_df['default'] = perf_df['default'].apply(lambda x: 1 if (x=='03') | (x=='09') else 0)\n",
    "\n",
    "            perf_df['prepayment']=0\n",
    "            perf_df.loc[(perf_df.cd_zero_bal=='01')&(perf_df.mths_remng!=0),'prepayment'] = 1 \n",
    "\n",
    "            de = perf_df[perf_df.default==1]\n",
    "            months_deliquecny = (pd.to_datetime(de.dt_zero_bal.values).year - pd.to_datetime(de.last_payment_date.values).year)*12 + (pd.to_datetime(de.dt_zero_bal.values).month - pd.to_datetime(de.last_payment_date.values).month)\n",
    "\n",
    "            c = perf_df[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01')]\n",
    "            o = (pd.to_datetime(c.dt_zero_bal.values).year - pd.to_datetime(c.last_payment_date.values).year)*12 + (pd.to_datetime(c.dt_zero_bal.values).month - pd.to_datetime(c.last_payment_date.values).month)\n",
    "\n",
    "            perf_df['lpi2zero'] = 0\n",
    "            perf_df.loc[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01'),'lpi2zero'] = o\n",
    "\n",
    "            de_i = perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1)] \n",
    "\n",
    "            perf_df['deliquent_interest'] = 0\n",
    "            perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1),'deliquent_interest'] = (de_i.lpi2zero) * (de_i.defaulted_upb - de_i.non_int_brng_upb) * (de_i.current_int_rt - 0.35) / 1200\n",
    "            \n",
    "            perf_df['total_costs'] = perf_df[['legal_costs','maint_pres_costs', 'taxes_ins_costs',\n",
    "                                  'misc_costs']].sum(axis=1)\n",
    "\n",
    "            perf_df['total_proceeds'] = perf_df[['mi_recoveries','net_sale_proceeds', 'non_mi_recoveries', 'expenses']].sum(axis=1)\n",
    "            perf_df['net_loss'] = perf_df['actual_loss']-perf_df['total_costs']\n",
    "\n",
    "            perf_df['loss_severity'] = 0\n",
    "\n",
    "            perf_df.loc[perf_df.net_loss!=0,'loss_severity'] = perf_df.loc[perf_df.net_loss!=0,['defaulted_upb','net_loss']].T.apply(lambda x: x[1]/x[0])\n",
    "            \n",
    "            perf_df.to_csv(file, mode='a', header=writeHeader2,index=False,encoding='utf-8')\n",
    "            writeHeader2=False\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ts = time.time()\n",
    "    foldername1= 'SampleInputFiles'\n",
    "    foldername2= 'HistoricalInputFiles' \n",
    "    \n",
    "    sampleOrigFiles=str(os.getcwd())+\"/\"+foldername1+\"/sample_orig_*.txt\"\n",
    "    samplePerfFiles=str(os.getcwd())+\"/\"+foldername1+\"/sample_svcg_*.txt\"\n",
    "    \n",
    "    historical_Files=str(os.getcwd())+\"/\"+foldername2+\"/historical_data1_*.txt\"\n",
    "    historical_timeFiles=str(os.getcwd())+\"/\"+foldername2+\"/historical_data1_*.txt\"\n",
    "    \n",
    "    \n",
    "    orig1_df = createOriginationCombined(sampleOrigFiles)\n",
    "    per1_df = createPerformanceCombined(samplePerfFiles)\n",
    "    \n",
    "    combined1_df = orig_df.merge(per_df,on='id_loan')\n",
    "    combined_df.to_csv('combined_SF_smaple_data.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "#     orig2_df = createOriginationCombined(historical_Files)\n",
    "#     per2_df = createPerformanceCombined(historical_timeFiles)\n",
    "    \n",
    "#     combined2_df = orig_df.merge(per_df,on='id_loan')\n",
    "#     combined_df.to_csv('combined_SF_historical_all_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dangar/Desktop/SF loan/FreddieMac_Single_Loan_Analysis_MachineLearning-master/SampleInputFiles/sample_svcg_*.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2016.txt:   0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2016.txt:   6%|▌         | 1/17 [01:23<22:09, 83.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2009.txt:   6%|▌         | 1/17 [01:23<22:09, 83.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2009.txt:  12%|█▏        | 2/17 [04:29<33:44, 134.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2010.txt:  12%|█▏        | 2/17 [04:29<33:44, 134.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2010.txt:  18%|█▊        | 3/17 [06:27<30:07, 129.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2008.txt:  18%|█▊        | 3/17 [06:27<30:08, 129.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2008.txt:  24%|██▎       | 4/17 [08:04<26:14, 121.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2005.txt:  24%|██▎       | 4/17 [08:04<26:14, 121.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2005.txt:  29%|██▉       | 5/17 [09:57<23:52, 119.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2004.txt:  29%|██▉       | 5/17 [09:57<23:52, 119.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2004.txt:  35%|███▌      | 6/17 [12:16<22:30, 122.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2001.txt:  35%|███▌      | 6/17 [12:16<22:30, 122.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2001.txt:  41%|████      | 7/17 [13:46<19:40, 118.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2017.txt:  41%|████      | 7/17 [13:46<19:40, 118.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2017.txt:  47%|████▋     | 8/17 [14:06<15:52, 105.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2007.txt:  47%|████▋     | 8/17 [14:06<15:52, 105.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2007.txt:  53%|█████▎    | 9/17 [15:43<13:58, 104.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2014.txt:  53%|█████▎    | 9/17 [15:43<13:58, 104.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2014.txt:  59%|█████▉    | 10/17 [17:11<12:02, 103.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2006.txt:  59%|█████▉    | 10/17 [17:11<12:02, 103.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2006.txt:  65%|██████▍   | 11/17 [18:51<10:16, 102.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2013.txt:  65%|██████▍   | 11/17 [18:51<10:16, 102.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2013.txt:  71%|███████   | 12/17 [20:23<08:29, 101.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2012.txt:  71%|███████   | 12/17 [20:23<08:29, 101.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2012.txt:  76%|███████▋  | 13/17 [22:00<06:46, 101.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_1999.txt:  76%|███████▋  | 13/17 [22:00<06:46, 101.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_1999.txt:  82%|████████▏ | 14/17 [23:35<05:03, 101.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2011.txt:  82%|████████▏ | 14/17 [23:35<05:03, 101.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2011.txt:  88%|████████▊ | 15/17 [25:09<03:21, 100.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2000.txt:  88%|████████▊ | 15/17 [25:09<03:21, 100.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2000.txt:  94%|█████████▍| 16/17 [26:36<01:39, 99.77s/it] \u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2002.txt:  94%|█████████▍| 16/17 [26:36<01:39, 99.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "Working on  sample_svcg_2002.txt: 100%|██████████| 17/17 [28:09<00:00, 99.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
