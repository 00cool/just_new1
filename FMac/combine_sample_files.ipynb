{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prgramitically Log in to Freddie Mac Webisite and download all the files based on request\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import sys   \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillNAN(df):\n",
    "    df['fico'] = df['fico'].fillna(9999)\n",
    "    df['flag_fthb']=df['flag_fthb'].fillna('X')\n",
    "    df['cd_msa']=df['cd_msa'].fillna(0)\n",
    "    df['mi_pct']=df['mi_pct'].fillna(999)\n",
    "    df['cnt_units']=df['cnt_units'].fillna(99)\n",
    "    df['occpy_sts']=df['occpy_sts'].fillna('X')\n",
    "    df['dti']=df['dti'].fillna(999)\n",
    "    df['ltv']=df['ltv'].fillna(999)\n",
    "    df['cltv']=df['cltv'].fillna(999)\n",
    "    df['channel']=df['channel'].fillna('X')\n",
    "    df['ppmt_pnlty']=df['ppmt_pnlty'].fillna('X')\n",
    "    df['prod_type']= df['prod_type'].fillna('X')\n",
    "    df['prop_type']=df['prop_type'].fillna('XX')\n",
    "    df['zipcode']=df['zipcode'].fillna('999999')\n",
    "    df['loan_purpose']=df['loan_purpose'].fillna('X')\n",
    "    df['cnt_borr']=df['cnt_borr'].fillna('99')\n",
    "    df['flag_sc']=df['flag_sc'].fillna('X')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changedatatype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']] = df[['fico','cd_msa','mi_pct','cnt_units','cltv','dti','orig_upb','ltv','orig_loan_term']].astype('float64')\n",
    "    df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']] = df[['flag_sc','flag_fthb','cnt_borr','occpy_sts','channel','ppmt_pnlty','zipcode','servicer_name','id_loan','loan_purpose','seller_name']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillNA(df):\n",
    "    df['delq_sts'] = df['delq_sts'].fillna('XX')\n",
    "    df['loan_age'] = df['loan_age'].fillna(999)\n",
    "    df['mths_remng'] = df['mths_remng'].fillna('XX')\n",
    "    df['repch_flag']=df['repch_flag'].fillna('X')\n",
    "    df['flag_mod']=df['flag_mod'].fillna('X')\n",
    "    df['cd_zero_bal']=df['cd_zero_bal'].fillna('00')\n",
    "    df['dt_zero_bal']=df['dt_zero_bal'].fillna('189901')\n",
    "    df['non_int_brng_upb']=df['non_int_brng_upb'].fillna(0)\n",
    "    df['dt_lst_pi']=df['dt_lst_pi'].fillna('189901')\n",
    "    df['mi_recoveries']=df['mi_recoveries'].fillna(0)\n",
    "    df['net_sale_proceeds']=df['net_sale_proceeds'].fillna('0.0')\n",
    "    df['non_mi_recoveries']=df['non_mi_recoveries'].fillna(0)\n",
    "    df['expenses']=df['expenses'].fillna(0)\n",
    "    df['legal_costs']=df['legal_costs'].fillna(0)\n",
    "    df['maint_pres_costs']=df['maint_pres_costs'].fillna(0)\n",
    "    df['taxes_ins_costs']=df['taxes_ins_costs'].fillna(0)\n",
    "    df['misc_costs']=df['misc_costs'].fillna(0)\n",
    "    df['actual_loss']=df['actual_loss'].fillna(0)\n",
    "    df['modcost']=df['modcost'].fillna(0)\n",
    "    df['stepmod_ind']=df['stepmod_ind'].fillna('X')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changedtype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']] = df[['current_upb','loan_age','mths_remng','current_int_rt','non_int_brng_upb','mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs',\n",
    "    'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost']].astype('float64')\n",
    "    df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']] = df[['id_loan','svcg_cycle','delq_sts','repch_flag','flag_mod', 'cd_zero_bal']].astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createOriginationCombined(str):\n",
    "    #print(str)\n",
    "    writeHeader1 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SampleOriginationCombined_1.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalOriginationCombined_1.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    "      \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            sample_df = pd.read_csv(f ,sep=\"|\", names=['fico','dt_first_pi','flag_fthb','dt_matr','cd_msa',\"mi_pct\",'cnt_units','occpy_sts','cltv','dti','orig_upb','ltv','int_rt','channel','ppmt_pnlty','prod_type','st', 'prop_type','zipcode','id_loan','loan_purpose', 'orig_loan_term','cnt_borr','seller_name','servicer_name','flag_sc'],skipinitialspace=True,dtype='unicode') \n",
    "            sample_df.flag_fthb[sample_df.flag_fthb=='9'] = 'X'\n",
    "            sample_df = fillNAN(sample_df)\n",
    "            sample_df = changedatatype(sample_df)\n",
    "            sample_df.dt_first_pi = pd.to_datetime(sample_df.dt_first_pi.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df.dt_matr = pd.to_datetime(sample_df.dt_matr.apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            sample_df['fico_bins'] = pd.cut(sample_df.fico[sample_df.fico<9999],5,include_lowest=True)\n",
    "            sample_df['cltv_bins'] = pd.cut(sample_df.cltv[sample_df.cltv<999],7,include_lowest=True)\n",
    "            sample_df['dti_bins'] = pd.cut(sample_df.dti[sample_df.dti<999],5,include_lowest=True)\n",
    "            sample_df['ltv_bins'] = pd.cut(sample_df.ltv[sample_df.ltv<999],5,include_lowest=True)\n",
    "            \n",
    "            sample_df['Year'] = ['19'+x if x=='99' else '20'+x for x in (sample_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "            sample_df.to_csv(file, mode='a', header=writeHeader1,index=False,encoding='utf-8')\n",
    "            writeHeader1=False\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPerformanceCombined(str): \n",
    "#     print(str)\n",
    "    writeHeader2 = True\n",
    "    if \"sample\" in str:\n",
    "        filename= \"SamplePerformanceCombinedSummary_1.csv\"\n",
    "    else:\n",
    "        filename= \"HistoricalPerformanceCombinedSummary_1.csv\"\n",
    "    \n",
    "    abc = tqdm(glob.glob(str))\n",
    " \n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as file:\n",
    "        for f in abc: \n",
    "            abc.set_description(\"Working on  {}\".format(f.split('\\\\')[-1]))\n",
    "            perf_df = pd.read_csv(f,sep=\"|\",header=None,skipinitialspace=True,dtype='unicode')\n",
    "            perf_df.columns =['id_loan','svcg_cycle','current_upb','delq_sts','loan_age','mths_remng', 'repch_flag',\n",
    "                              'flag_mod','cd_zero_bal', 'dt_zero_bal','current_int_rt','non_int_brng_upb','dt_lst_pi',\n",
    "                              'mi_recoveries','net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs', \n",
    "                              'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost','stepmod_ind']\n",
    "#             perf_df['delq_sts'] = [ 999 if x=='R' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "#             perf_df['delq_sts'] = [ 0 if x=='XX' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "            perf_df.loc[(perf_df.net_sale_proceeds=='U')|(perf_df.net_sale_proceeds=='C'),'net_sale_proceeds'] = '0.0'\n",
    "#             perf_df['net_sale_proceeds'] = [ '0.0' if x=='C' else x for x in (perf_df['net_sale_proceeds'].apply(lambda x: x))]\n",
    "\n",
    "            perf_df = fillNA(perf_df)\n",
    "            perf_df = changedtype(perf_df)\n",
    "\n",
    "            ve =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='03')|(perf_df.cd_zero_bal=='09')].index)\n",
    "            h = ve.groupby(by='id_loan').last().reset_index()\n",
    "            defauled_upb = h.loc[h.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='03')|(perf_df.cd_zero_bal=='09')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            ve1 =perf_df.drop(perf_df[(perf_df.cd_zero_bal=='01')].index)\n",
    "            h1 = ve1.groupby(by='id_loan').last().reset_index()\n",
    "            prepaid_upb = h1.loc[h1.id_loan.isin(perf_df[(perf_df.cd_zero_bal=='01')].id_loan.values),['id_loan','current_upb']]\n",
    "\n",
    "            lpi = perf_df.loc[(perf_df.delq_sts=='0'),['id_loan','svcg_cycle']]\n",
    "            lpi =lpi.groupby(by='id_loan').last().reset_index()\n",
    "            delq_sts_180 = perf_df.loc[(perf_df.delq_sts=='6'),['id_loan','svcg_cycle','current_upb']]\n",
    "            delq_sts_180 = delq_sts_180.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df = perf_df.groupby(by='id_loan').last().reset_index()\n",
    "\n",
    "            perf_df['delq_sts_180_date'] = '189901'\n",
    "            perf_df['last_payment_date'] = '189901'\n",
    "            perf_df['delq_sts_180_upb'] = 0\n",
    "            perf_df['defaulted_upb'] = 0\n",
    "            perf_df['prepaid_upb'] = 0\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_date'] = delq_sts_180.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(delq_sts_180.id_loan.values),'delq_sts_180_upb'] = delq_sts_180.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(lpi.id_loan.values),'last_payment_date'] = lpi.svcg_cycle.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(defauled_upb.id_loan.values),'defaulted_upb'] = defauled_upb.current_upb.values\n",
    "            perf_df.loc[perf_df.id_loan.isin(prepaid_upb.id_loan.values),'prepaid_upb'] = prepaid_upb.current_upb.values\n",
    "\n",
    "#             perf_df = perf_df.drop(perf_df[perf_df.cd_zero_bal=='06'].index)\n",
    "#             perf_df = perf_df.drop('repch_flag',axis=1)\n",
    "\n",
    "            perf_df.dt_lst_pi = pd.to_datetime(perf_df.dt_lst_pi.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.dt_zero_bal = pd.to_datetime(perf_df.dt_zero_bal.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.delq_sts_180_date = pd.to_datetime(perf_df.delq_sts_180_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "            perf_df.last_payment_date = pd.to_datetime(perf_df.last_payment_date.astype('str').apply(lambda x: x[:4] +'/'+x[4:]))\n",
    "\n",
    "            perf_df['GT_90_days_deliquecy'] = perf_df.delq_sts.values\n",
    "            perf_df['GT_90_days_deliquecy'] = perf_df['GT_90_days_deliquecy'].apply(lambda x: 0 if (x=='0') | (x=='1') | (x=='2')|(x=='XX')  else 1)\n",
    "\n",
    "            perf_df['default'] = perf_df.cd_zero_bal.values\n",
    "            perf_df['default'] = perf_df['default'].apply(lambda x: 1 if (x=='03') | (x=='09') else 0)\n",
    "\n",
    "            perf_df['prepayment']=0\n",
    "            perf_df.loc[(perf_df.cd_zero_bal=='01')&(perf_df.mths_remng!=0),'prepayment'] = 1 \n",
    "\n",
    "            de = perf_df[perf_df.default==1]\n",
    "            months_deliquecny = (pd.to_datetime(de.dt_zero_bal.values).year - pd.to_datetime(de.last_payment_date.values).year)*12 + (pd.to_datetime(de.dt_zero_bal.values).month - pd.to_datetime(de.last_payment_date.values).month)\n",
    "\n",
    "            c = perf_df[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01')]\n",
    "            o = (pd.to_datetime(c.dt_zero_bal.values).year - pd.to_datetime(c.last_payment_date.values).year)*12 + (pd.to_datetime(c.dt_zero_bal.values).month - pd.to_datetime(c.last_payment_date.values).month)\n",
    "\n",
    "            perf_df['lpi2zero'] = 0\n",
    "            perf_df.loc[(perf_df.dt_lst_pi!='1899-01-01')&(perf_df.dt_zero_bal!='1899-01-01'),'lpi2zero'] = o\n",
    "\n",
    "            de_i = perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1)] \n",
    "\n",
    "            perf_df['deliquent_interest'] = 0\n",
    "            perf_df.loc[(perf_df.lpi2zero!=0)&(perf_df.default==1),'deliquent_interest'] = (de_i.lpi2zero) * (de_i.defaulted_upb - de_i.non_int_brng_upb) * (de_i.current_int_rt - 0.35) / 1200\n",
    "            \n",
    "            perf_df['total_costs'] = perf_df[['legal_costs','maint_pres_costs', 'taxes_ins_costs',\n",
    "                                  'misc_costs']].sum(axis=1)\n",
    "\n",
    "            perf_df['total_proceeds'] = perf_df[['mi_recoveries','net_sale_proceeds', 'non_mi_recoveries', 'expenses']].sum(axis=1)\n",
    "            perf_df['net_loss'] = perf_df['actual_loss']-perf_df['total_costs']\n",
    "\n",
    "            perf_df['loss_severity'] = 0\n",
    "\n",
    "            perf_df.loc[perf_df.net_loss!=0,'loss_severity'] = perf_df.loc[perf_df.net_loss!=0,['defaulted_upb','net_loss']].T.apply(lambda x: x[1]/x[0])\n",
    "            \n",
    "            perf_df.to_csv(file, mode='a', header=writeHeader2,index=False,encoding='utf-8')\n",
    "            writeHeader2=False\n",
    "    return perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    ts = time.time()\n",
    "    foldername= 'SampleInputFiles'\n",
    "    \n",
    "    sampleOrigFiles=str(os.getcwd())+\"/\"+foldername+\"/sample_orig_*.txt\"\n",
    "    samplePerfFiles=str(os.getcwd())+\"/\"+foldername+\"/sample_svcg_*.txt\"\n",
    "    \n",
    "    orig_df = createOriginationCombined(sampleOrigFiles)\n",
    "    per_df = createPerformanceCombined(samplePerfFiles)\n",
    "    \n",
    "    combined_df = orig_df.join(per_df,on='id_loan',lsuffix='_')\n",
    "    combined_df.drop('id_loan_',axis=1,inplace=True)\n",
    "    combined_df.to_csv('combined_SF_smaple_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "Working on  SampleInputFiles\\sample_orig_1999.txt:   0%|                                        | 0/17 [00:00<?, ?it/s]\n",
      "Working on  SampleInputFiles\\sample_orig_1999.txt:   6%|█▉                              | 1/17 [00:02<00:40,  2.51s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2000.txt:   6%|█▉                              | 1/17 [00:02<00:40,  2.51s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2000.txt:  12%|███▊                            | 2/17 [00:04<00:37,  2.48s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2001.txt:  12%|███▊                            | 2/17 [00:04<00:37,  2.49s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2001.txt:  18%|█████▋                          | 3/17 [00:07<00:34,  2.50s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2002.txt:  18%|█████▋                          | 3/17 [00:07<00:34,  2.50s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2002.txt:  24%|███████▌                        | 4/17 [00:10<00:32,  2.54s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2004.txt:  24%|███████▌                        | 4/17 [00:10<00:32,  2.54s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2004.txt:  29%|█████████▍                      | 5/17 [00:12<00:30,  2.57s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2005.txt:  29%|█████████▍                      | 5/17 [00:12<00:30,  2.57s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2005.txt:  35%|███████████▎                    | 6/17 [00:15<00:28,  2.59s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2006.txt:  35%|███████████▎                    | 6/17 [00:15<00:28,  2.59s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2006.txt:  41%|█████████████▏                  | 7/17 [00:18<00:25,  2.59s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2007.txt:  41%|█████████████▏                  | 7/17 [00:18<00:25,  2.59s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2007.txt:  47%|███████████████                 | 8/17 [00:20<00:23,  2.60s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2008.txt:  47%|███████████████                 | 8/17 [00:20<00:23,  2.60s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2008.txt:  53%|████████████████▉               | 9/17 [00:23<00:20,  2.61s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2009.txt:  53%|████████████████▉               | 9/17 [00:23<00:20,  2.61s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2009.txt:  59%|██████████████████▏            | 10/17 [00:26<00:18,  2.62s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2010.txt:  59%|██████████████████▏            | 10/17 [00:26<00:18,  2.62s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2010.txt:  65%|████████████████████           | 11/17 [00:28<00:15,  2.63s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2011.txt:  65%|████████████████████           | 11/17 [00:28<00:15,  2.63s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2011.txt:  71%|█████████████████████▉         | 12/17 [00:31<00:13,  2.65s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2012.txt:  71%|█████████████████████▉         | 12/17 [00:31<00:13,  2.65s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2012.txt:  76%|███████████████████████▋       | 13/17 [00:34<00:10,  2.65s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2013.txt:  76%|███████████████████████▋       | 13/17 [00:34<00:10,  2.65s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2013.txt:  82%|█████████████████████████▌     | 14/17 [00:36<00:07,  2.64s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2014.txt:  82%|█████████████████████████▌     | 14/17 [00:36<00:07,  2.64s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2014.txt:  88%|███████████████████████████▎   | 15/17 [00:39<00:05,  2.63s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2016.txt:  88%|███████████████████████████▎   | 15/17 [00:39<00:05,  2.63s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2016.txt:  94%|█████████████████████████████▏ | 16/17 [00:42<00:02,  2.64s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2017.txt:  94%|█████████████████████████████▏ | 16/17 [00:42<00:02,  2.64s/it]\n",
      "Working on  SampleInputFiles\\sample_orig_2017.txt: 100%|███████████████████████████████| 17/17 [00:44<00:00,  2.61s/it]\n",
      "\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "Working on  SampleInputFiles\\sample_svcg_1999.txt:   0%|                                        | 0/17 [00:00<?, ?it/s]\n",
      "Working on  SampleInputFiles\\sample_svcg_1999.txt:   6%|█▉                              | 1/17 [00:27<07:25, 27.85s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2000.txt:   6%|█▉                              | 1/17 [00:27<07:25, 27.85s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2000.txt:  12%|███▊                            | 2/17 [00:44<05:35, 22.33s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2001.txt:  12%|███▊                            | 2/17 [00:44<05:35, 22.34s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2001.txt:  18%|█████▋                          | 3/17 [01:04<05:01, 21.54s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2002.txt:  18%|█████▋                          | 3/17 [01:04<05:01, 21.54s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2002.txt:  24%|███████▌                        | 4/17 [01:28<04:46, 22.03s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2004.txt:  24%|███████▌                        | 4/17 [01:28<04:46, 22.03s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2004.txt:  29%|█████████▍                      | 5/17 [02:05<05:01, 25.13s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2005.txt:  29%|█████████▍                      | 5/17 [02:05<05:01, 25.14s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2005.txt:  35%|███████████▎                    | 6/17 [02:42<04:57, 27.03s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2006.txt:  35%|███████████▎                    | 6/17 [02:42<04:57, 27.03s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2006.txt:  41%|█████████████▏                  | 7/17 [03:12<04:35, 27.57s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2007.txt:  41%|█████████████▏                  | 7/17 [03:12<04:35, 27.57s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2007.txt:  47%|███████████████                 | 8/17 [03:41<04:09, 27.67s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2008.txt:  47%|███████████████                 | 8/17 [03:41<04:09, 27.67s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2008.txt:  53%|████████████████▉               | 9/17 [04:05<03:38, 27.27s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2009.txt:  53%|████████████████▉               | 9/17 [04:05<03:38, 27.27s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2009.txt:  59%|██████████████████▏            | 10/17 [04:31<03:09, 27.14s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2010.txt:  59%|██████████████████▏            | 10/17 [04:31<03:09, 27.14s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2010.txt:  65%|████████████████████           | 11/17 [04:56<02:41, 27.00s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2011.txt:  65%|████████████████████           | 11/17 [04:56<02:41, 27.00s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2011.txt:  71%|█████████████████████▉         | 12/17 [05:21<02:13, 26.76s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2012.txt:  71%|█████████████████████▉         | 12/17 [05:21<02:13, 26.76s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2012.txt:  76%|███████████████████████▋       | 13/17 [05:47<01:46, 26.74s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2013.txt:  76%|███████████████████████▋       | 13/17 [05:47<01:46, 26.74s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2013.txt:  82%|█████████████████████████▌     | 14/17 [06:09<01:19, 26.40s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2014.txt:  82%|█████████████████████████▌     | 14/17 [06:09<01:19, 26.40s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2014.txt:  88%|███████████████████████████▎   | 15/17 [06:27<00:51, 25.82s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2016.txt:  88%|███████████████████████████▎   | 15/17 [06:27<00:51, 25.82s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2016.txt:  94%|█████████████████████████████▏ | 16/17 [06:37<00:24, 24.85s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2017.txt:  94%|█████████████████████████████▏ | 16/17 [06:37<00:24, 24.85s/it]\n",
      "Working on  SampleInputFiles\\sample_svcg_2017.txt: 100%|███████████████████████████████| 17/17 [06:39<00:00, 23.48s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foldername= 'SampleInputFiles'\n",
    "p = str(os.getcwd())+\"/\"+foldername+\"/sample_svcg_*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_1999.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2000.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2001.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2002.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2004.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2005.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2006.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2007.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2008.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2009.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2010.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2011.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2012.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2013.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2014.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2016.txt',\n",
       " 'C:\\\\Users\\\\Dangar\\\\Desktop\\\\SF loan\\\\SF new/SampleInputFiles\\\\sample_svcg_2017.txt']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample_svcg_2017.txt'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(glob.glob(p)[-1]).split('\\\\')[-1]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
